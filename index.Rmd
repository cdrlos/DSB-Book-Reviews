---
title: "Predicting book success"
author: "Samal Abdikerimova, Ravi Donepudi, Carlos Salinas, and Xiran Yu"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_depth: 2
    theme: united
    highlight: default
    self_contained: yes
---

# Book review statistics

```{r setup, include = FALSE}
library("broom")
library("forcats")
library("tidyverse")
library("gganimate")
```

[rgoodreads]: https://github.com/Famguy/rgoodreads
[goodreads-kaggle]: https://www.kaggle.com/jealousleopard/goodreadsbooks/
# About the data
There is a Goodreads API and an R interface to accompany it, however we will be using the data set found on Kaggle [here][goodreads-kaggle] because it is proving far too difficult to gather and process data from the Goodreads API.

First we will import the data and take a look at its contents. 
```{r import-books_csv, message = FALSE, warning = FALSE}
books <- read_csv("data/books.csv") %>%
    rename(rating = average_rating,
           total_ratings = ratings_count,
           lang = language_code,
           pages = num_pages) %>%
    na.omit()
books
```

So it looks like we are working with `r ncol(books)` variables, and `r nrow(books)` observations. Some of these variables are redundant and, for our purposes, can be ignored.

```{r }
books$bookID <- NULL
books$isbn <- NULL
books$isbn13 <- NULL
```
# Publication language
Since we speak English we'd like to focus solely on English language books. But first let's see how many of them we have

```{r, message = FALSE, warning = FALSE}
books %>%
    subset(is.na(as.numeric(lang))) %>%
    subset(!is.na(lang)) %>%
    group_by(lang) %>%
    tally() %>%
    arrange(desc(n)) %>%
    slice(1:10) %>%
    ggplot(aes(x = factor(lang, levels = lang), y = n, fill = lang)) +
    geom_bar(stat = "identity") +
    labs(title = "Title number of books by language",
         x = "language",
         y = "number of books") +
    theme(axis.text.x = element_text(angle=90, hjust=1))
```

So the overwhelming majority of the data is in `eng` so we don't loose much by ignoring the other publications. However, it looks like US and Great Britain version of books fall under a different language tag (and if we search hard Canadian too). For our purposes `"en-CA", `"en-GB"`, and `en-US` are the same so let us clean up the data a little.

```{r eng_replace, message = FALSE, warning = FALSE}
books$lang <- books %>%
    pull(lang) %>%
    str_replace_all("en*(g|-GB|-US|-CA)", "eng")
eng_books <- books %>% filter(lang == "eng" & rating >= 2.5)
```

Next let's get an idea of the distribution of ratings for English language books.

```{r plot ratings, message = FALSE, warning = FALSE}
eng_books %>%
    group_by(rating) %>%
    summarize(total_books = n()) %>%
    ungroup() %>%
    ggplot(aes(x = rating)) +
    geom_histogram(aes(y = total_books/1.00001, fill = rating),
                   stat = "identity",
                   freq = FALSE) +
    labs(title = "Total number of books per rating",
         x = "average rating",
         y = "number of books")
```

This actually very closely resembles a normal curve with mean `r mean(eng_books$rating)` and standard deviation `r sd(eng_books$rating)`.


And what about publications per year?

```{r, message = FALSE, warning = FALSE}
eng_books <- eng_books %>%
    mutate(publication_year = as.numeric(str_sub(publication_date, -4)))
```

```{r publications per year, message = FALSE, warning = FALSE}
eng_books %>% group_by(publication_year) %>%
    summarize(total_books = n()) %>%
    ungroup() %>%
    ggplot(aes(x = publication_year, y = total_books)) +
    geom_point() +
    xlim(1900, 2020) +
    labs(x = "publication year",
         y = "books published")
```

The scatter plot shows an exponential trend until about 2007 for which we can use a linear model by taking the log of the number of publications.

```{r, message = FALSE, rating = FALSE}
books_per_year <- eng_books %>% group_by(publication_year) %>%
    summarize(total_books = n()) %>%
    arrange(desc(total_books)) %>%
    ungroup()

model_publish_books <- books_per_year %>%
    filter(publication_year <= 2006) %>%
    lm(log(total_books) ~ publication_year, .)

model_publish_books %>% tidy()

estimate_2020 <-
    predict(model_publish_books,
            newdata = data.frame(publication_year = seq(2015,2020)))
```

However because the data does not include every book ever published, but rather is curated for most reviews, this model is not necessarily accurate. In fact, it is necessarily inaccurate since publications per year are actually increasing exponentially as can be seen in the following [analysis](https://ourworldindata.org/books).

# Prolific writers
Who are the top rated authors? Naively we can look at the average rating of each author as follows.

```{r naive top authors, message = FALSE, warning = FALSE}
eng_books %>%
    group_by(authors) %>%
    summarize(average_rating = sum(rating)/n()) %>%
    arrange(desc(average_rating)) %>%
    ungroup() %>%
    slice(1:10)
```

Who are these people, I've never heard of them?

So highly rated authors are not necessarily notable ones, perhaps the sum total of the ratings is a better indicator of *good author*.

```{r good books, message = FALSE, warning = FALSE}
prolific_writer_names <- eng_books %>%
    group_by(authors) %>%
    summarize(book_count = n(),
              sum_rating = sum(rating)) %>%
    arrange(desc(sum_rating)) %>%
    slice(1:10) %>%
    pull(authors)

prolific_writers <- eng_books %>% filter(authors %in% prolific_writer_names)

prolific_writers %>%
    (function(...) {
        tmp <- tibble(...)
        tmp$authors <- tmp$authors %>%
            str_replace_all("Margaret Weis/Tracy Hickman",
                            "Weis/Hickman")
        tmp}) %>%
    group_by(authors) %>%
    summarize(book_count = n(),
              sum_rating = sum(rating)) %>%
    arrange(desc(sum_rating)) %>%
    slice(1:10) %>%
    ggplot(aes(factor(authors, levels = authors), sum_rating, fill = authors)) +
    geom_col() +
    coord_flip() +
    labs(title = "Author rankings",
         y = "author",
         x = "sum rating") +
    scale_fill_brewer(palette="Spectral")
```

OK, this is much better and most of them are recognizable. Now let's take a look at their average rating.

```{r average rating, message = FALSE, rating = FALSE}
prolific_writers %>%
    (function(...) {
        tmp <- tibble(...)
        tmp$authors <- tmp$authors %>%
            str_replace_all("Margaret Weis/Tracy Hickman",
                            "Weis/Hickman")
        tmp}) %>%
    group_by(authors) %>%
    summarize(avg_rat = sum(rating)/n()) %>%
    ungroup() %>%
    ggplot(aes(x = authors, y = avg_rat, fill = authors)) +
    geom_bar(stat = "identity") +
    labs(title = "Top 10 average author rating",
          x = "auhor",
          y = "average rating") +
    theme(axis.text.x = element_text(angle = 90))
```

## Modeling Stephen King
So Stephen King is the most prolific writer in this data set and also has fairly good ratings. In this section we will take a look at models for predicting the popularity of a hypothetical future publication of Stephen King.

```{r, message = FALSE, rating = FALSE}
stephen_king <- books %>% filter(authors == "Stephen King" &
                                 title != "Blood and Smoke" &
                                 title != "LT's Theory of Pets")
sk_model <- lm(rating ~ pages, stephen_king)
sk_model %>% tidy()

predict(sk_model,
        newdata = data.frame(pages = c(300)))
```

We are excluding the books Blood and Smoke and LT's Theory of Pets because they are audio books.

```{r, message = FALSE, rating = FALSE}
stephen_king %>% summarize(mean = mean(pages))
```

# Publishers
Next we will at the top 10 publishers by rating. We will first need to turn the publisher name into a factor to more easily work with it.

```{r, message = FALSE, warning = FALSE}
eng_books$publisher <- factor(eng_books$publisher)
```

Next let us see who the top 10 publishers are.

```{r, message = FALSE, warning = FALSE }
top_10_publishers <- eng_books %>%
    group_by(publisher) %>%
    summarize(total_books = n()) %>%
    arrange(desc(total_books)) %>%
    slice(1:10) %>%
    pull(publisher)

eng_books_tp <- eng_books %>%
    filter(publisher %in% top_10_publishers)
```

Next let us see how the popularity of their publications have changed since 2000.

```{r , message = FALSE, warning = FALSE}
eng_books_tp %>%
    filter(publication_year >= 2000 &
           publication_year <= 2007) %>%
    ggplot(aes(x = fct_reorder(publisher, rating),
               y = rating, color = publisher)) +
    geom_boxplot() +
    labs(title = "Publisher rating in {closest_state}",
         x = "publisher") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    transition_states(publication_year,
                      transition_length = 2,
                      state_length = 4) +
    enter_fade() +
    exit_shrink() +
    ease_aes('sine-in-out')
```

As we can see, the medium rating stays almost the same, fluctuating around 4.0 aver the years.
